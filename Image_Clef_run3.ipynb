{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkdDOIsdavWl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Load the training data\n",
        "train_data = df\n",
        "train_data.dropna(inplace=True)\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data['text_en'], train_data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Load the pre-trained DistilBERT model\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# Encode the training and validation data to get sentence embeddings\n",
        "X_train_embeddings = model.encode(X_train.tolist())\n",
        "X_val_embeddings = model.encode(X_val.tolist())\n",
        "\n",
        "# Define hyperparameters for logistic regression\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Initialize logistic regression classifier\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='f1', verbose=1)\n",
        "grid_search.fit(X_train_embeddings, y_train)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the classifier on the validation set\n",
        "val_predictions = best_classifier.predict(X_val_embeddings)\n",
        "val_f1 = f1_score(y_val, val_predictions)\n",
        "print(\"Validation F1 Score:\", val_f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained classifier\n",
        "joblib.dump(best_classifier, 'power-distil-logistic-f1_.joblib')\n",
        "\n",
        "print(\"Classifier saved successfully!\")\n"
      ],
      "metadata": {
        "id": "U7VS1jl0bW2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = best_classifier.predict(X_train_embeddings)\n",
        "val_f1 = f1_score(y_train, test_predictions)\n",
        "print(\"Validation F1 Score:\", val_f1)"
      ],
      "metadata": {
        "id": "VsS4XNU8bbl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "loaded_classifier = joblib.load('/content/drive/MyDrive/Touche clef/Distil-logistic-f1_74.joblib')"
      ],
      "metadata": {
        "id": "FzxIs_WWbeJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "rIdOkwE3bgbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_data = df['text_en']\n",
        "test_data.fillna('not possible',inplace=True)\n",
        "\n",
        "X_test_embeddings = model.encode(test_data.tolist())\n",
        "# Make predictions on the test data\n",
        "test_predictions = loaded_classifier.predict(X_test_embeddings)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "output_df = pd.DataFrame({'id': df['id'], 'label': test_predictions})\n",
        "output_df.to_csv(\"predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "UgON4dtIbipa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "val_f1 = f1_score(df['label'], test_predictions)\n",
        "print(\"Validation F1 Score:\", val_f1)"
      ],
      "metadata": {
        "id": "LjGxAA-Bbj99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to):\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"Error: The file {zip_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Check if the directory to extract to exists, create it if it doesn't\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "\n",
        "    # Unzip the file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "        print(f\"Successfully unzipped {zip_path} to {extract_to}\")\n",
        "\n",
        "# Example usage\n",
        "zip_path = '/content/drive/MyDrive/Touche clef/ideology-power-st-testset.zip'\n",
        "extract_to = '/content/cont'\n",
        "\n",
        "unzip_file(zip_path, extract_to)\n"
      ],
      "metadata": {
        "id": "eE8z7CVyblh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all=\"ua\"\n",
        "df1 = pd.read_table('/content/cont/power/power-'+all+'-test.tsv')\n",
        "test_data = df1['text_en']\n",
        "test_data.fillna('not possible',inplace=True)\n",
        "\n",
        "X_test_embeddings = model.encode(test_data.tolist())\n",
        "# Make predictions on the test data\n",
        "test_predictions = loaded_classifier.predict(X_test_embeddings)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "output_df = pd.DataFrame({'id': df1['id'], 'label': test_predictions})\n",
        "output_df.to_csv(\"pixel-power-\"+all+\"-run3.tsv\", index=False, header=False, sep='\\t')"
      ],
      "metadata": {
        "id": "91E7q2bdbokN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_f1 = f1_score(df1['label'], test_predictions)\n",
        "print(\"Validation F1 Score:\", val_f1)"
      ],
      "metadata": {
        "id": "GFikLRgDbqRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}